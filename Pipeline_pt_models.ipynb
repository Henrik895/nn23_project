{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ucbJBeNC73IM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y1QtIF2U73OA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-157-g5178d41 Python-3.9.16 torch-2.0.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\henri\\Desktop\\nato_project\\repo\\nn23_project\\generator\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 276 layers, 35248920 parameters, 0 gradients, 48.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# YOLO model\n",
    "yolo_model =  torch.hub.load('yolov5', 'custom', 'models/model_yolo.pt', source='local')\n",
    "\n",
    "# Configurations\n",
    "\n",
    "img_dir = \"images\"\n",
    "save_dir = img_dir + \"_pred\"\n",
    "results_file = 'results.json'\n",
    "crop_shape = (64,64)\n",
    "\n",
    "# Transformations\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=64),\n",
    "        A.RandomCrop(height=64, width=64),\n",
    "        A.Normalize(mean=0.5, std=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification models\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"label\": \"infantry\",\n",
    "        \"path\": \"models/model_infantry.pt\",\n",
    "        \"model\": None\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"anti-tank\",\n",
    "        \"path\": \"models/model_at.pt\",\n",
    "        \"model\": None\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"supply\",\n",
    "        \"path\": \"models/model_supply.pt\",\n",
    "        \"model\": None\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"hq\",\n",
    "        \"path\": \"models/model_hq.pt\",\n",
    "        \"model\": None\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"medic\",\n",
    "        \"path\": \"models/model_medic.pt\",\n",
    "        \"model\": None\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"reconnaissance\",\n",
    "        \"path\": \"models/model_recce.pt\",\n",
    "        \"model\": None\n",
    "    }\n",
    "    # Extend the list with additional models\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    loaded_model = torch.jit.load(model[\"path\"], map_location=torch.device(\"cpu\"))\n",
    "    loaded_model.eval()\n",
    "    model[\"model\"] = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_symbols(save_results=True):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    detections = []\n",
    "    \n",
    "    for img in os.listdir(img_dir):\n",
    "        if \"img\" not in img:\n",
    "            continue\n",
    "        \n",
    "        print('Processing image', img)\n",
    "        \n",
    "        detection = {\n",
    "            \"img\": img,\n",
    "            \"symbols\": [],\n",
    "        }\n",
    "        \n",
    "        canvas = cv2.imread(img_dir+'/'+img)\n",
    "        canvas_gray = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        symbol_locs = yolo_model(canvas)\n",
    "        \n",
    "        for i, d in symbol_locs.pandas().xyxy[0].iterrows():\n",
    "            symbol = {\n",
    "                \"xmin\": int(d.xmin),\n",
    "                \"ymin\": int(d.ymin),\n",
    "                \"xmax\": int(np.ceil(d.xmax)),\n",
    "                \"ymax\": int(np.ceil(d.ymax)),\n",
    "                \"labels\": [],\n",
    "            }\n",
    "            \n",
    "            unit_symbol = canvas_gray[int(d.ymin):int(np.ceil(d.ymax)), int(d.xmin):int(np.ceil(d.xmax))]\n",
    "            unit_symbol = transforms(image=unit_symbol)[\"image\"]\n",
    "            \n",
    "            translate_label = 0 # For writing the labels on the image by amount of pixels\n",
    "            for model in models:\n",
    "                logits = model[\"model\"](unit_symbol.unsqueeze(0))\n",
    "                \n",
    "                if logits.shape[1] == 2:\n",
    "                    classify_result = torch.argmax(logits) == 1\n",
    "                else:\n",
    "                    classify_result = torch.round(torch.sigmoid(logits)).squeeze()\n",
    "                    \n",
    "                if classify_result:\n",
    "                    symbol[\"labels\"].append(model[\"label\"])\n",
    "                    cv2.rectangle(\n",
    "                        canvas, \n",
    "                        (int(d.xmin), int(d.ymin)), \n",
    "                        (int(np.ceil(d.xmax)), int(np.ceil(d.ymax))), \n",
    "                        (255,0,0), 2)\n",
    "                    canvas = cv2.putText(\n",
    "                        canvas, \n",
    "                        model[\"label\"], \n",
    "                        (int(d.xmin)-10, int(d.ymin)-translate_label),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                        (255, 0, 255), 1, cv2.LINE_AA)\n",
    "                    translate_label += 18\n",
    "                    \n",
    "            detection[\"symbols\"].append(symbol)\n",
    "        \n",
    "        cv2.imwrite(f\"{save_dir}/{img}\", canvas)\n",
    "        detections.append(detection)\n",
    "                    \n",
    "    json_result = json.dumps(detections, indent=4)\n",
    "    \n",
    "    if save_results:\n",
    "        print('Saving results to', results_file)\n",
    "        with open(results_file, 'w') as file:\n",
    "            file.write(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image img0.jpg\n",
      "Processing image img1.jpg\n",
      "Processing image img10.jpg\n",
      "Processing image img11.jpg\n",
      "Processing image img12.jpg\n",
      "Processing image img13.jpg\n",
      "Processing image img14.jpg\n",
      "Processing image img15.jpg\n",
      "Processing image img16.jpg\n",
      "Processing image img17.jpg\n",
      "Processing image img18.jpg\n",
      "Processing image img19.jpg\n",
      "Processing image img2.jpg\n",
      "Processing image img20.jpg\n",
      "Processing image img21.jpg\n",
      "Processing image img22.jpg\n",
      "Processing image img23.jpg\n",
      "Processing image img24.jpg\n",
      "Processing image img25.jpg\n",
      "Processing image img26.jpg\n",
      "Processing image img27.jpg\n",
      "Processing image img28.jpg\n",
      "Processing image img29.jpg\n",
      "Processing image img3.jpg\n",
      "Processing image img30.jpg\n",
      "Processing image img31.jpg\n",
      "Processing image img32.jpg\n",
      "Processing image img33.jpg\n",
      "Processing image img34.jpg\n",
      "Processing image img35.jpg\n",
      "Processing image img36.jpg\n",
      "Processing image img37.jpg\n",
      "Processing image img38.jpg\n",
      "Processing image img39.jpg\n",
      "Processing image img4.jpg\n",
      "Processing image img5.jpg\n",
      "Processing image img6.jpg\n",
      "Processing image img7.jpg\n",
      "Processing image img8.jpg\n",
      "Processing image img9.jpg\n",
      "Saving results to results.json\n"
     ]
    }
   ],
   "source": [
    "detect_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
