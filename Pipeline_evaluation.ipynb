{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = './results.json'\n",
    "labels_dir = './test/unit_labels/test/'\n",
    "img_dir = './test/images/test/'\n",
    "models_dir = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, 'r') as fp:\n",
    "    results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_models = {}\n",
    "# for file in os.scandir(models_dir):\n",
    "#     if file.is_file() and file.name.startswith('model') and file.name.endswith('.pt'):\n",
    "#         model_name = file.name.split('model_')[1][:-3]\n",
    "#         if 'yolo' not in model_name:\n",
    "#             map_models[model_name] = len(map_models)\n",
    "\n",
    "units = [['infantry',\n",
    "          'anti_tank',\n",
    "          'armour',\n",
    "          'wheeled',\n",
    "          'unit_tactical'],\n",
    "         ['recce',\n",
    "          'medic',\n",
    "          'signal',\n",
    "          'hq_unit',\n",
    "          'supply',\n",
    "          'artillery',\n",
    "          'mortar',\n",
    "          'air_defence'],\n",
    "         ['infantry',\n",
    "          'anti_tank',\n",
    "          'recce',\n",
    "          'medic',\n",
    "          'signal'],\n",
    "         ['motorized', 'cannon'],\n",
    "         ['team', 'squad', 'half-platoon', 'platoon', 'company',  # Currently repetition because unit sizes are sampled with uniform distirubution\n",
    "          'battalion']]  # 'brigade', 'regiment', 'division']\n",
    "\n",
    "units = set([j for sub in units for j in sub])\n",
    "\n",
    "map_models = {}\n",
    "for unit in units:\n",
    "    map_models[unit] = len(map_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(results):\n",
    "    for s in row['symbols']:\n",
    "        s['used'] = 0\n",
    "\n",
    "column_names = [\"actual\", \"predicted\", \"correct\",\n",
    "                \"incorrect\", \"missed\"]  # , \"x1\", \"x2\", \"y1\", \"y2\"]\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "for i, row in enumerate(results):\n",
    "    cur_img = row['img'].strip()\n",
    "    img = cv2.imread(f\"{img_dir}{cur_img}\")\n",
    "    img_txt = cur_img.split('.')[0] + '.txt'\n",
    "    with open(f'{labels_dir}{img_txt}') as fp:\n",
    "        for line in fp:\n",
    "            splits = line.strip().split(\" \")\n",
    "            x_c, y_c, h, w = map(float, splits[1:])\n",
    "            actual = splits[0].strip().split(\"__\")[1:]\n",
    "            height, width, channels = img.shape\n",
    "            x_c, y_c, w, h = float(x_c)*width, float(y_c) * \\\n",
    "                height, float(w)*width, float(h)*height\n",
    "\n",
    "            predicted = []\n",
    "            for s in row['symbols']:\n",
    "                if s['used'] == 0:\n",
    "                    if s['xmin'] <= x_c and x_c <= s['xmax'] and s['ymin'] <= y_c and y_c <= s['ymax']:\n",
    "                        predicted = s['labels']\n",
    "                        s['used'] = 1\n",
    "                        break\n",
    "\n",
    "            dif = set(actual) - set(predicted)\n",
    "            missed = len(dif)\n",
    "            correct = len(actual) - missed\n",
    "            incorrect = len(predicted) - correct\n",
    "            # print(map_labels(map_models, actual))\n",
    "            # print(map_labels(map_models, predicted))\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame(\n",
    "                [[actual, predicted, correct, incorrect, missed]], columns=column_names)], ignore_index=True)\n",
    "\n",
    "for row in results:\n",
    "    for s in row['symbols']:\n",
    "        if s['used'] == 0:\n",
    "            df = pd.concat([df, pd.DataFrame([[[], s['labels'], 0, 0, len(\n",
    "                s['labels'])]], columns=column_names)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>missed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[mortar, company]</td>\n",
       "      <td>[mortar, company]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[supply, armour, company]</td>\n",
       "      <td>[armour, company]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[armour, half-platoon]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[infantry, company]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supply, squad]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual          predicted correct incorrect missed\n",
       "0          [mortar, company]  [mortar, company]       2         0      0\n",
       "1  [supply, armour, company]  [armour, company]       2         0      1\n",
       "2     [armour, half-platoon]          [company]       0         1      2\n",
       "3        [infantry, company]          [company]       1         0      1\n",
       "4            [supply, squad]          [company]       0         1      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_labels = set([j for sub in df[['actual', 'predicted']].apply(lambda x: x[0] + x[1], axis=1).to_list() for j in sub])\n",
    "# for label in actual_labels:\n",
    "#     if label not in map_models:\n",
    "#         map_models[label] = len(map_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(map_models, input_list):\n",
    "    out = [0] * len(map_models)\n",
    "    for label in input_list:\n",
    "        if label in map_models:\n",
    "            out[map_models[label]] = 1\n",
    "        elif label == 'anti-tank':\n",
    "            out[map_models['anti_tank']] = 1\n",
    "        else:\n",
    "            # out[map_models['other']] = 1\n",
    "            raise ValueError(f'Add label {label}')\n",
    "    return out\n",
    "\n",
    "\n",
    "df['actual_encoded'] = df['actual'].apply(lambda x: map_labels(map_models, x))\n",
    "df['predicted_encoded'] = df['predicted'].apply(lambda x: map_labels(map_models, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>missed</th>\n",
       "      <th>actual_encoded</th>\n",
       "      <th>predicted_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[mortar, company]</td>\n",
       "      <td>[mortar, company]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[supply, armour, company]</td>\n",
       "      <td>[armour, company]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[armour, half-platoon]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[infantry, company]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[supply, squad]</td>\n",
       "      <td>[company]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual          predicted correct incorrect missed  \\\n",
       "0          [mortar, company]  [mortar, company]       2         0      0   \n",
       "1  [supply, armour, company]  [armour, company]       2         0      1   \n",
       "2     [armour, half-platoon]          [company]       0         1      2   \n",
       "3        [infantry, company]          [company]       1         0      1   \n",
       "4            [supply, squad]          [company]       0         1      2   \n",
       "\n",
       "                                      actual_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                   predicted_encoded  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = np.sum(df['actual_encoded'].to_list(), axis=0)\n",
    "# y_pred = np.sum(df['predicted_encoded'].to_list(), axis=0)\n",
    "y_true = df['actual_encoded'].tolist()\n",
    "y_pred = df['predicted_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(map_models.items(), key=lambda x: x[1])\n",
    "sorted_labels = [item[0] for item in sorted_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "# y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_dict={}\n",
    "report_dict = {}\n",
    "\n",
    "for label_col in range(len(sorted_labels)):\n",
    "    y_true_label = y_true[:, label_col]\n",
    "    y_pred_label = y_pred[:, label_col]\n",
    "    conf_mat_dict[sorted_labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    report_dict[sorted_labels[label_col]] = classification_report(y_pred=y_pred_label, y_true=y_true_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label infantry:\n",
      "[[238   0]\n",
      " [ 42   0]]\n",
      "Confusion matrix for label supply:\n",
      "[[252   0]\n",
      " [ 28   0]]\n",
      "Confusion matrix for label platoon:\n",
      "[[212   0]\n",
      " [ 64   4]]\n",
      "Confusion matrix for label artillery:\n",
      "[[269   0]\n",
      " [  2   9]]\n",
      "Confusion matrix for label medic:\n",
      "[[260   0]\n",
      " [ 20   0]]\n",
      "Confusion matrix for label air_defence:\n",
      "[[267   0]\n",
      " [ 13   0]]\n",
      "Confusion matrix for label unit_tactical:\n",
      "[[271   0]\n",
      " [  9   0]]\n",
      "Confusion matrix for label mortar:\n",
      "[[262   4]\n",
      " [  5   9]]\n",
      "Confusion matrix for label cannon:\n",
      "[[245   0]\n",
      " [ 35   0]]\n",
      "Confusion matrix for label anti_tank:\n",
      "[[242   0]\n",
      " [ 12  26]]\n",
      "Confusion matrix for label team:\n",
      "[[241   0]\n",
      " [ 38   1]]\n",
      "Confusion matrix for label recce:\n",
      "[[260   0]\n",
      " [ 20   0]]\n",
      "Confusion matrix for label squad:\n",
      "[[240   0]\n",
      " [ 39   1]]\n",
      "Confusion matrix for label battalion:\n",
      "[[241  21]\n",
      " [ 15   3]]\n",
      "Confusion matrix for label armour:\n",
      "[[195   0]\n",
      " [ 34  51]]\n",
      "Confusion matrix for label signal:\n",
      "[[262   0]\n",
      " [ 18   0]]\n",
      "Confusion matrix for label motorized:\n",
      "[[254   0]\n",
      " [ 26   0]]\n",
      "Confusion matrix for label half-platoon:\n",
      "[[229   0]\n",
      " [ 51   0]]\n",
      "Confusion matrix for label hq_unit:\n",
      "[[256   0]\n",
      " [ 24   0]]\n",
      "Confusion matrix for label wheeled:\n",
      "[[253   0]\n",
      " [ 26   1]]\n",
      "Confusion matrix for label company:\n",
      "[[ 30 186]\n",
      " [  0  64]]\n"
     ]
    }
   ],
   "source": [
    "for label, matrix in conf_mat_dict.items():\n",
    "    print(\"Confusion matrix for label {}:\".format(label))\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report matrix for label infantry:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       238\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.85       280\n",
      "   macro avg       0.42      0.50      0.46       280\n",
      "weighted avg       0.72      0.85      0.78       280\n",
      "\n",
      "Classification report matrix for label supply:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       252\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.45      0.50      0.47       280\n",
      "weighted avg       0.81      0.90      0.85       280\n",
      "\n",
      "Classification report matrix for label platoon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       212\n",
      "           1       1.00      0.06      0.11        68\n",
      "\n",
      "    accuracy                           0.77       280\n",
      "   macro avg       0.88      0.53      0.49       280\n",
      "weighted avg       0.82      0.77      0.68       280\n",
      "\n",
      "Classification report matrix for label artillery:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       269\n",
      "           1       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.99       280\n",
      "   macro avg       1.00      0.91      0.95       280\n",
      "weighted avg       0.99      0.99      0.99       280\n",
      "\n",
      "Classification report matrix for label medic:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       260\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.46      0.50      0.48       280\n",
      "weighted avg       0.86      0.93      0.89       280\n",
      "\n",
      "Classification report matrix for label air_defence:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       267\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.48      0.50      0.49       280\n",
      "weighted avg       0.91      0.95      0.93       280\n",
      "\n",
      "Classification report matrix for label unit_tactical:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       271\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.48      0.50      0.49       280\n",
      "weighted avg       0.94      0.97      0.95       280\n",
      "\n",
      "Classification report matrix for label mortar:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       266\n",
      "           1       0.69      0.64      0.67        14\n",
      "\n",
      "    accuracy                           0.97       280\n",
      "   macro avg       0.84      0.81      0.82       280\n",
      "weighted avg       0.97      0.97      0.97       280\n",
      "\n",
      "Classification report matrix for label cannon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       245\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.44      0.50      0.47       280\n",
      "weighted avg       0.77      0.88      0.82       280\n",
      "\n",
      "Classification report matrix for label anti_tank:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       242\n",
      "           1       1.00      0.68      0.81        38\n",
      "\n",
      "    accuracy                           0.96       280\n",
      "   macro avg       0.98      0.84      0.89       280\n",
      "weighted avg       0.96      0.96      0.95       280\n",
      "\n",
      "Classification report matrix for label team:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       241\n",
      "           1       1.00      0.03      0.05        39\n",
      "\n",
      "    accuracy                           0.86       280\n",
      "   macro avg       0.93      0.51      0.49       280\n",
      "weighted avg       0.88      0.86      0.80       280\n",
      "\n",
      "Classification report matrix for label recce:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       260\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.93       280\n",
      "   macro avg       0.46      0.50      0.48       280\n",
      "weighted avg       0.86      0.93      0.89       280\n",
      "\n",
      "Classification report matrix for label squad:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       240\n",
      "           1       1.00      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.86       280\n",
      "   macro avg       0.93      0.51      0.49       280\n",
      "weighted avg       0.88      0.86      0.80       280\n",
      "\n",
      "Classification report matrix for label battalion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       262\n",
      "           1       0.12      0.17      0.14        18\n",
      "\n",
      "    accuracy                           0.87       280\n",
      "   macro avg       0.53      0.54      0.54       280\n",
      "weighted avg       0.89      0.87      0.88       280\n",
      "\n",
      "Classification report matrix for label armour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       195\n",
      "           1       1.00      0.60      0.75        85\n",
      "\n",
      "    accuracy                           0.88       280\n",
      "   macro avg       0.93      0.80      0.83       280\n",
      "weighted avg       0.90      0.88      0.87       280\n",
      "\n",
      "Classification report matrix for label signal:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       262\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.94       280\n",
      "   macro avg       0.47      0.50      0.48       280\n",
      "weighted avg       0.88      0.94      0.90       280\n",
      "\n",
      "Classification report matrix for label motorized:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       254\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.45      0.50      0.48       280\n",
      "weighted avg       0.82      0.91      0.86       280\n",
      "\n",
      "Classification report matrix for label half-platoon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       229\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.82       280\n",
      "   macro avg       0.41      0.50      0.45       280\n",
      "weighted avg       0.67      0.82      0.74       280\n",
      "\n",
      "Classification report matrix for label hq_unit:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96       256\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.46      0.50      0.48       280\n",
      "weighted avg       0.84      0.91      0.87       280\n",
      "\n",
      "Classification report matrix for label wheeled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       253\n",
      "           1       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.91       280\n",
      "   macro avg       0.95      0.52      0.51       280\n",
      "weighted avg       0.92      0.91      0.87       280\n",
      "\n",
      "Classification report matrix for label company:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.24       216\n",
      "           1       0.26      1.00      0.41        64\n",
      "\n",
      "    accuracy                           0.34       280\n",
      "   macro avg       0.63      0.57      0.33       280\n",
      "weighted avg       0.83      0.34      0.28       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, matrix in report_dict.items():\n",
    "    print(\"Classification report matrix for label {}:\".format(label))\n",
    "    print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
