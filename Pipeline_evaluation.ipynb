{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = './results.json'\n",
    "labels_dir = './test/labels/'\n",
    "img_dir = './test/images/'\n",
    "models_dir = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file, 'r') as fp:\n",
    "    results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_models = {}\n",
    "# for file in os.scandir(models_dir):\n",
    "#     if file.is_file() and file.name.startswith('model') and file.name.endswith('.pt'):\n",
    "#         model_name = file.name.split('model_')[1][:-3]\n",
    "#         if 'yolo' not in model_name:\n",
    "#             map_models[model_name] = len(map_models)\n",
    "\n",
    "units = [['infantry',\n",
    "          'anti_tank',\n",
    "          'armour',\n",
    "          'wheeled',\n",
    "          'unit_tactical'],\n",
    "         ['recce',\n",
    "          'medic',\n",
    "          'signal',\n",
    "          'hq_unit',\n",
    "          'supply',\n",
    "          'artillery',\n",
    "          'engineer',\n",
    "          'mortar',\n",
    "          'missile',\n",
    "          'air_defence'],\n",
    "         ['infantry',\n",
    "          'anti_tank',\n",
    "          'recce',\n",
    "          'sniper',\n",
    "          'medic',\n",
    "          'signal'],\n",
    "         ['motorized', 'cannon'],\n",
    "         ['team', 'squad', 'half-platoon', 'platoon', 'company',  # Currently repetition because unit sizes are sampled with uniform distirubution\n",
    "          'battalion']]  # 'brigade', 'regiment', 'division']\n",
    "\n",
    "units = set([j for sub in units for j in sub])\n",
    "\n",
    "map_models = {}\n",
    "for unit in units:\n",
    "    map_models[unit] = len(map_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(results):\n",
    "    for s in row['symbols']:\n",
    "        s['used'] = 0\n",
    "\n",
    "column_names = [\"actual\", \"predicted\", \"correct\",\n",
    "                \"incorrect\", \"missed\"]  # , \"x1\", \"x2\", \"y1\", \"y2\"]\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "for i, row in enumerate(results):\n",
    "    cur_img = row['img'].strip()\n",
    "    img = cv2.imread(f\"{img_dir}{cur_img}\")\n",
    "    img_txt = cur_img.split('.')[0] + '.txt'\n",
    "    with open(f'{labels_dir}{img_txt}') as fp:\n",
    "        for line in fp:\n",
    "            splits = line.strip().split(\" \")\n",
    "            x_c, y_c, h, w = map(float, splits[1:])\n",
    "            actual = splits[0].strip().split(\"__\")[1:]\n",
    "            height, width, channels = img.shape\n",
    "            x_c, y_c, w, h = float(x_c)*width, float(y_c) * \\\n",
    "                height, float(w)*width, float(h)*height\n",
    "\n",
    "            predicted = []\n",
    "            for s in row['symbols']:\n",
    "                if s['used'] == 0:\n",
    "                    if s['xmin'] <= x_c and x_c <= s['xmax'] and s['ymin'] <= y_c and y_c <= s['ymax']:\n",
    "                        predicted = s['labels']\n",
    "                        s['used'] = 1\n",
    "                        break\n",
    "\n",
    "            dif = set(actual) - set(predicted)\n",
    "            missed = len(dif)\n",
    "            correct = len(actual) - missed\n",
    "            incorrect = len(predicted) - correct\n",
    "            # print(map_labels(map_models, actual))\n",
    "            # print(map_labels(map_models, predicted))\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame(\n",
    "                [[actual, predicted, correct, incorrect, missed]], columns=column_names)], ignore_index=True)\n",
    "\n",
    "for row in results:\n",
    "    for s in row['symbols']:\n",
    "        if s['used'] == 0:\n",
    "            df = pd.concat([df, pd.DataFrame([[[], s['labels'], 0, 0, len(\n",
    "                s['labels'])]], columns=column_names)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>missed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[armour, half-platoon]</td>\n",
       "      <td>[company, company]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[missile, wheeled, team]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hq_unit, wheeled, team]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hq_unit, half-platoon]</td>\n",
       "      <td>[company, company]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mortar, wheeled, company]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       actual           predicted correct incorrect missed\n",
       "0      [armour, half-platoon]  [company, company]       0         2      2\n",
       "1    [missile, wheeled, team]     [company, team]       1         1      2\n",
       "2    [hq_unit, wheeled, team]     [company, team]       1         1      2\n",
       "3     [hq_unit, half-platoon]  [company, company]       0         2      2\n",
       "4  [mortar, wheeled, company]     [company, team]       1         1      2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_labels = set([j for sub in df[['actual', 'predicted']].apply(lambda x: x[0] + x[1], axis=1).to_list() for j in sub])\n",
    "# for label in actual_labels:\n",
    "#     if label not in map_models:\n",
    "#         map_models[label] = len(map_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(map_models, input_list):\n",
    "    out = [0] * len(map_models)\n",
    "    for label in input_list:\n",
    "        if label in map_models:\n",
    "            out[map_models[label]] = 1\n",
    "        elif label == 'anti-tank':\n",
    "            out[map_models['anti_tank']] = 1\n",
    "        elif label == 'engineers':\n",
    "            out[map_models['engineer']] = 1\n",
    "        elif label == 'hq-unit':\n",
    "            out[map_models['hq_unit']] = 1\n",
    "        else:\n",
    "            # out[map_models['other']] = 1\n",
    "            raise ValueError(f'Add label {label}')\n",
    "    return out\n",
    "\n",
    "\n",
    "df['actual_encoded'] = df['actual'].apply(lambda x: map_labels(map_models, x))\n",
    "df['predicted_encoded'] = df['predicted'].apply(lambda x: map_labels(map_models, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>missed</th>\n",
       "      <th>actual_encoded</th>\n",
       "      <th>predicted_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[armour, half-platoon]</td>\n",
       "      <td>[company, company]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[missile, wheeled, team]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hq_unit, wheeled, team]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hq_unit, half-platoon]</td>\n",
       "      <td>[company, company]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mortar, wheeled, company]</td>\n",
       "      <td>[company, team]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       actual           predicted correct incorrect missed  \\\n",
       "0      [armour, half-platoon]  [company, company]       0         2      2   \n",
       "1    [missile, wheeled, team]     [company, team]       1         1      2   \n",
       "2    [hq_unit, wheeled, team]     [company, team]       1         1      2   \n",
       "3     [hq_unit, half-platoon]  [company, company]       0         2      2   \n",
       "4  [mortar, wheeled, company]     [company, team]       1         1      2   \n",
       "\n",
       "                                      actual_encoded  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                   predicted_encoded  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = np.sum(df['actual_encoded'].to_list(), axis=0)\n",
    "# y_pred = np.sum(df['predicted_encoded'].to_list(), axis=0)\n",
    "y_true = df['actual_encoded'].tolist()\n",
    "y_pred = df['predicted_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(map_models.items(), key=lambda x: x[1])\n",
    "sorted_labels = [item[0] for item in sorted_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_true)\n",
    "# y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_dict={}\n",
    "report_dict = {}\n",
    "\n",
    "for label_col in range(len(sorted_labels)):\n",
    "    y_true_label = y_true[:, label_col]\n",
    "    y_pred_label = y_pred[:, label_col]\n",
    "    conf_mat_dict[sorted_labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    report_dict[sorted_labels[label_col]] = classification_report(y_pred=y_pred_label, y_true=y_true_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label missile:\n",
      "[[2681   12]\n",
      " [  78   31]]\n",
      "Confusion matrix for label armour:\n",
      "[[1918    0]\n",
      " [ 742  142]]\n",
      "Confusion matrix for label sniper:\n",
      "[[2716    0]\n",
      " [  86    0]]\n",
      "Confusion matrix for label squad:\n",
      "[[2150   63]\n",
      " [ 430  159]]\n",
      "Confusion matrix for label air_defence:\n",
      "[[2700    0]\n",
      " [ 102    0]]\n",
      "Confusion matrix for label mortar:\n",
      "[[2682   28]\n",
      " [  43   49]]\n",
      "Confusion matrix for label hq_unit:\n",
      "[[2568    0]\n",
      " [ 149   85]]\n",
      "Confusion matrix for label cannon:\n",
      "[[2514    0]\n",
      " [ 241   47]]\n",
      "Confusion matrix for label supply:\n",
      "[[2452  115]\n",
      " [ 146   89]]\n",
      "Confusion matrix for label anti_tank:\n",
      "[[2336    1]\n",
      " [ 331  134]]\n",
      "Confusion matrix for label infantry:\n",
      "[[2325    2]\n",
      " [ 352  123]]\n",
      "Confusion matrix for label medic:\n",
      "[[2685    0]\n",
      " [  50   67]]\n",
      "Confusion matrix for label signal:\n",
      "[[2689    0]\n",
      " [  95   18]]\n",
      "Confusion matrix for label platoon:\n",
      "[[2237    0]\n",
      " [ 511   54]]\n",
      "Confusion matrix for label recce:\n",
      "[[2694    2]\n",
      " [  72   34]]\n",
      "Confusion matrix for label wheeled:\n",
      "[[2539    0]\n",
      " [ 258    5]]\n",
      "Confusion matrix for label engineer:\n",
      "[[2671    6]\n",
      " [ 100   25]]\n",
      "Confusion matrix for label motorized:\n",
      "[[2620    0]\n",
      " [ 175    7]]\n",
      "Confusion matrix for label artillery:\n",
      "[[2695    1]\n",
      " [  13   93]]\n",
      "Confusion matrix for label battalion:\n",
      "[[2498  123]\n",
      " [ 170   11]]\n",
      "Confusion matrix for label half-platoon:\n",
      "[[2247    0]\n",
      " [ 435  120]]\n",
      "Confusion matrix for label unit_tactical:\n",
      "[[1957  786]\n",
      " [  12   47]]\n",
      "Confusion matrix for label company:\n",
      "[[ 141 2117]\n",
      " [   4  540]]\n",
      "Confusion matrix for label team:\n",
      "[[ 647 1788]\n",
      " [   7  360]]\n"
     ]
    }
   ],
   "source": [
    "for label, matrix in conf_mat_dict.items():\n",
    "    print(\"Confusion matrix for label {}:\".format(label))\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report matrix for label missile:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2693\n",
      "           1       0.72      0.28      0.41       109\n",
      "\n",
      "    accuracy                           0.97      2802\n",
      "   macro avg       0.85      0.64      0.70      2802\n",
      "weighted avg       0.96      0.97      0.96      2802\n",
      "\n",
      "Classification report matrix for label armour:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1918\n",
      "           1       1.00      0.16      0.28       884\n",
      "\n",
      "    accuracy                           0.74      2802\n",
      "   macro avg       0.86      0.58      0.56      2802\n",
      "weighted avg       0.81      0.74      0.66      2802\n",
      "\n",
      "Classification report matrix for label sniper:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2716\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.97      2802\n",
      "   macro avg       0.48      0.50      0.49      2802\n",
      "weighted avg       0.94      0.97      0.95      2802\n",
      "\n",
      "Classification report matrix for label squad:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90      2213\n",
      "           1       0.72      0.27      0.39       589\n",
      "\n",
      "    accuracy                           0.82      2802\n",
      "   macro avg       0.77      0.62      0.64      2802\n",
      "weighted avg       0.81      0.82      0.79      2802\n",
      "\n",
      "Classification report matrix for label air_defence:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2700\n",
      "           1       0.00      0.00      0.00       102\n",
      "\n",
      "    accuracy                           0.96      2802\n",
      "   macro avg       0.48      0.50      0.49      2802\n",
      "weighted avg       0.93      0.96      0.95      2802\n",
      "\n",
      "Classification report matrix for label mortar:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2710\n",
      "           1       0.64      0.53      0.58        92\n",
      "\n",
      "    accuracy                           0.97      2802\n",
      "   macro avg       0.81      0.76      0.78      2802\n",
      "weighted avg       0.97      0.97      0.97      2802\n",
      "\n",
      "Classification report matrix for label hq_unit:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2568\n",
      "           1       1.00      0.36      0.53       234\n",
      "\n",
      "    accuracy                           0.95      2802\n",
      "   macro avg       0.97      0.68      0.75      2802\n",
      "weighted avg       0.95      0.95      0.94      2802\n",
      "\n",
      "Classification report matrix for label cannon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2514\n",
      "           1       1.00      0.16      0.28       288\n",
      "\n",
      "    accuracy                           0.91      2802\n",
      "   macro avg       0.96      0.58      0.62      2802\n",
      "weighted avg       0.92      0.91      0.89      2802\n",
      "\n",
      "Classification report matrix for label supply:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2567\n",
      "           1       0.44      0.38      0.41       235\n",
      "\n",
      "    accuracy                           0.91      2802\n",
      "   macro avg       0.69      0.67      0.68      2802\n",
      "weighted avg       0.90      0.91      0.90      2802\n",
      "\n",
      "Classification report matrix for label anti_tank:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      2337\n",
      "           1       0.99      0.29      0.45       465\n",
      "\n",
      "    accuracy                           0.88      2802\n",
      "   macro avg       0.93      0.64      0.69      2802\n",
      "weighted avg       0.90      0.88      0.85      2802\n",
      "\n",
      "Classification report matrix for label infantry:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      2327\n",
      "           1       0.98      0.26      0.41       475\n",
      "\n",
      "    accuracy                           0.87      2802\n",
      "   macro avg       0.93      0.63      0.67      2802\n",
      "weighted avg       0.89      0.87      0.84      2802\n",
      "\n",
      "Classification report matrix for label medic:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2685\n",
      "           1       1.00      0.57      0.73       117\n",
      "\n",
      "    accuracy                           0.98      2802\n",
      "   macro avg       0.99      0.79      0.86      2802\n",
      "weighted avg       0.98      0.98      0.98      2802\n",
      "\n",
      "Classification report matrix for label signal:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2689\n",
      "           1       1.00      0.16      0.27       113\n",
      "\n",
      "    accuracy                           0.97      2802\n",
      "   macro avg       0.98      0.58      0.63      2802\n",
      "weighted avg       0.97      0.97      0.95      2802\n",
      "\n",
      "Classification report matrix for label platoon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      2237\n",
      "           1       1.00      0.10      0.17       565\n",
      "\n",
      "    accuracy                           0.82      2802\n",
      "   macro avg       0.91      0.55      0.54      2802\n",
      "weighted avg       0.85      0.82      0.75      2802\n",
      "\n",
      "Classification report matrix for label recce:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      2696\n",
      "           1       0.94      0.32      0.48       106\n",
      "\n",
      "    accuracy                           0.97      2802\n",
      "   macro avg       0.96      0.66      0.73      2802\n",
      "weighted avg       0.97      0.97      0.97      2802\n",
      "\n",
      "Classification report matrix for label wheeled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2539\n",
      "           1       1.00      0.02      0.04       263\n",
      "\n",
      "    accuracy                           0.91      2802\n",
      "   macro avg       0.95      0.51      0.49      2802\n",
      "weighted avg       0.92      0.91      0.87      2802\n",
      "\n",
      "Classification report matrix for label engineer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2677\n",
      "           1       0.81      0.20      0.32       125\n",
      "\n",
      "    accuracy                           0.96      2802\n",
      "   macro avg       0.89      0.60      0.65      2802\n",
      "weighted avg       0.96      0.96      0.95      2802\n",
      "\n",
      "Classification report matrix for label motorized:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2620\n",
      "           1       1.00      0.04      0.07       182\n",
      "\n",
      "    accuracy                           0.94      2802\n",
      "   macro avg       0.97      0.52      0.52      2802\n",
      "weighted avg       0.94      0.94      0.91      2802\n",
      "\n",
      "Classification report matrix for label artillery:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2696\n",
      "           1       0.99      0.88      0.93       106\n",
      "\n",
      "    accuracy                           1.00      2802\n",
      "   macro avg       0.99      0.94      0.96      2802\n",
      "weighted avg       0.99      1.00      0.99      2802\n",
      "\n",
      "Classification report matrix for label battalion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      2621\n",
      "           1       0.08      0.06      0.07       181\n",
      "\n",
      "    accuracy                           0.90      2802\n",
      "   macro avg       0.51      0.51      0.51      2802\n",
      "weighted avg       0.88      0.90      0.89      2802\n",
      "\n",
      "Classification report matrix for label half-platoon:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      2247\n",
      "           1       1.00      0.22      0.36       555\n",
      "\n",
      "    accuracy                           0.84      2802\n",
      "   macro avg       0.92      0.61      0.63      2802\n",
      "weighted avg       0.87      0.84      0.80      2802\n",
      "\n",
      "Classification report matrix for label unit_tactical:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.71      0.83      2743\n",
      "           1       0.06      0.80      0.11        59\n",
      "\n",
      "    accuracy                           0.72      2802\n",
      "   macro avg       0.53      0.76      0.47      2802\n",
      "weighted avg       0.97      0.72      0.82      2802\n",
      "\n",
      "Classification report matrix for label company:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.06      0.12      2258\n",
      "           1       0.20      0.99      0.34       544\n",
      "\n",
      "    accuracy                           0.24      2802\n",
      "   macro avg       0.59      0.53      0.23      2802\n",
      "weighted avg       0.82      0.24      0.16      2802\n",
      "\n",
      "Classification report matrix for label team:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.27      0.42      2435\n",
      "           1       0.17      0.98      0.29       367\n",
      "\n",
      "    accuracy                           0.36      2802\n",
      "   macro avg       0.58      0.62      0.35      2802\n",
      "weighted avg       0.88      0.36      0.40      2802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, matrix in report_dict.items():\n",
    "    print(\"Classification report matrix for label {}:\".format(label))\n",
    "    print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
